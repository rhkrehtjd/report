{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89caf89-9e8c-4dbc-9ce7-1ceb1994a692",
   "metadata": {},
   "source": [
    "## 사이킷런으로 시작하는 머신러닝\n",
    "### 붓꽃 품종 예측하기\n",
    "##### -먼저 붓꽃 데이터를 사용할수 있게 해주고, 분류에 쓸 함수들을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d6aed1e-d00c-4944-87ee-57ac2d4a41df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris_data= iris.data\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00bfcc7-76cb-45bb-8023-ac06fabb21b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2226dd9d-4d4a-4f16-9068-3c980eaa2a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42dba9f-a123-4a8a-a0f9-8491cb83c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names) \n",
    "iris_df\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb5e8bf-4e6c-4886-a65f-5638d7078136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -iris_df['label'] = iris.target   \n",
    "# (iris_df) <-이 데이터 프레임에 iris.target인 0~2를 함께 볼수 있도록 'label'이라는 이름의 열을 추가해 줍니다. \n",
    "iris_df['label'] = iris.target \n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0415266-b751-412f-af20-345fc243c1fe",
   "metadata": {},
   "source": [
    "##### -학습된 모델의 성능을 알아보기 위해 학습용 데이터와 테스트용 데이터를 분리시켜 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506693a7-8aa1-46d3-be38-9fb7d371ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터중 80프로는 학습용, 나머지 20프로는 테스트용으로 분할한다\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffeb7f-f60a-4810-a98f-dac233124e83",
   "metadata": {},
   "source": [
    "##### -의사결정 트리로 학습 후 예측하고, 성능(정확도)평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b232a26-eb99-410a-bfbb-7ea9d1d94a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습 시킬때 의사결정 트리씀\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd3b981-915c-4aa4-b028-2407b10086c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,\n",
       "       0, 1, 0, 0, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dt_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909fb9ad-2557-4b27-80ad-4d1740dbc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.866667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:4f}'.format(accuracy_score(y_test,pred)))\n",
    "# 테스트용 레이블 데이터(y_test)와 예측된 레이블 데이터(pred)의 정확성이 약 0.98입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef569701-334e-4c41-a393-413b3c3a6cad",
   "metadata": {},
   "source": [
    "### 사이킷런의 기반 프레임워크 익히기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910a929c-ac30-4687-915d-0c895af8f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data=load_iris()\n",
    "print(type(iris_data))\n",
    "# 결과가 Bunch로 나오는 데 번치 클래스는 파이썬 딕셔너리 자료형과 유사함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e63917f-fa2f-40a1-a660-6428dbda4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "#데이터 세트에 내장돼 있는 대부분의 데이터 세트는 아래와 같이 딕셔너리 형태의 값을 반환함.\n",
    "keys=iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)\n",
    "#data가 피처 값, target이 레이블 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54f38ed8-a97a-477b-9726-5f109ac5dae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#딕셔너리 형태에서 피처 데이터 값을 추출하려면 데이터 세트.data or 데이터 세트['data']헤주면 됨\n",
    "#나는 데이터 세트 설명과 각 피처의 설명을 나타내는 DESCR을 쳐봄. DESCR는 표에는 안나오니까..?\n",
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f043a4bc-d1e4-4aab-b7d8-314c04d212dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " feature_names 의 type: <class 'list'>\n",
      " feature_names 의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target의 type: <class 'numpy.ndarray'>\n",
      " target의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(' feature_names 의 type:', type(iris_data.feature_names))\n",
    "print(' feature_names 의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data['feature_names'])\n",
    "\n",
    "print('\\n target의 type:', type(iris_data.target))\n",
    "print(' target의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf8e40-7b3a-47a0-82de-b168d93a963b",
   "metadata": {},
   "source": [
    "### k폴드 교차검증 \n",
    "* 데이터 편중을 막고자, 여러번 다양하게 데이터 구성시켜 학습 및 평가\n",
    "* 데이터를 k덩이로 나눠서 k개 중 1개는 검증, 나머지 k-1 개는 학습으로 분할하는 걸 각각 다르게! k번한다.\n",
    "* (1) 폴드 세트 설정 \n",
    "* (2) for 루프 반복으로 학습 및 테스트 데이터의 인덱스를 추출 \n",
    "* (3) 반복적으로 학습과 예측을 수행하고 예측수행을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9003115-080b-487a-9bb7-0fcae3c46354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "iris.data.shape[0]\n",
    "# +) shape[0] 은 행의 개수, shape[1] 은 열의 개수 인가봄\n",
    "# 근데 여기서 붓꽃 데이터가 150개라고 하는데 shape로 보면 행이 150, 열이 4개\n",
    "# 그래서 데이터는 600개 라고 생각할수 있지만, 4개의 열을 큰 하나로 보나봄. 큰 틀에서 그 피처를 가지는 꽃 종류는 같은거니까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "908dcee5-7e46-4d5f-b63e-cf6ac90b099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도:1.0, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#1 학습 용:[ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "#2 교차 검증 정확도:0.9667, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#2 학습 용:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "#3 교차 검증 정확도:0.8667, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#3 학습 용:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "#4 교차 검증 정확도:0.9333, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#4 학습 용:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "#5 교차 검증 정확도:0.7333, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#5 학습 용:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "#(1)\n",
    "kfold=KFold(n_splits=5)\n",
    "cv_accuracy=[]\n",
    "\n",
    "# 교차검증의 횟수를 세기 위한 변수로 n_iter를 지정해 줍니다.\n",
    "n_iter=0\n",
    "\n",
    "#(2)\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test=features[train_index], features[test_index]\n",
    "    y_train, y_test=label[train_index], label[test_index]\n",
    "#(3)    \n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy=np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도:{1}, 학습 데이터 크기: {2}, 검증 데이터 크기:{3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    print('#{0} 학습 용:{1}'.format(n_iter, train_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "#개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))\n",
    "\n",
    "#iteration이란..음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71d42218-d122-4c5d-b97d-3b3265cf9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환해줌.\n",
    "# 문자열.split() 함수는 문자열을 일정한 규칙으로 잘라서 리스트로 만들어 주는 함수.\n",
    "# n_splits 는 데이터 분할 수 입니다. 그러면 이 숫자만큼 인덱스로 분할함. 전체 데이터 수를 넘을 수 없습니다. (=분할 파라미터를 설정)\n",
    "# +) shuffle은  매번 데이터를 분할하기전 섞을지 말지 여부를 선택합니다. 기본값이 트루인가?\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환해줌.\n",
    "# StratifiedKFold 사용을 위해서는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 \n",
    "# split( ) 메서드에 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 넣어줘야한다.\n",
    "# 문자열.split() 함수는 문자열을 일정한 규칙으로 잘라서 리스트로 만들어 주는 함수.\n",
    "# 그리고 split() 함수 써주면 값이 인덱스로 반환됨\n",
    "# 위에서 검증(=테스트용) 세트 인덱스만 출력한 이유가 학습용까지 출력하면 #1에서는 30~149 #2에서는 0~29, 60~149..너무 많아서 그럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5be873a-85ce-4df9-a1ce-ceaa8a65dec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "       146, 147, 148, 149])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93e3397-6664-455f-8adc-7d05075c3232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd02aaa9-2743-426f-86ce-ae880926b0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_df=pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()\n",
    "# 시리즈의 값이 정수, 문자열, 카테고리 값인 경우에는 value_counts() 메서드로 각각의 값이 나온 횟수를 셀 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6faf70a6-9a81-40b4-af72-c1d31f7c7d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증:1\n",
      "\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증:2\n",
      "\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증:3\n",
      "\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter +=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증:{0}\\n'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
    "    \n",
    "# iloc[0]은 전체 데이터 프레임에서 0번째 행의 값들만 추출해라\n",
    "# print형식 써줄때 값 입력 부분에서 언제 format쓰고 언제는 걍 값 그자체를 써주는가..질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64c97cbc-d2dc-4a7d-8900-b980335faaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001F557762890>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c75cba0c-3d20-478d-833d-91a91258e60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d149ab01-3090-4d07-b262-69cb1c3bf30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "       113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "       126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
       "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c996f490-67de-4e95-b04b-247585697be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    1\n",
       "99    1\n",
       "Name: label, Length: 100, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7df958e-9ca2-4652-93cd-304d38824477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계속 헷갈리는 것-(값 추출과 열 추가)\n",
    "# '딕셔너리 형태'에서 피처 데이터 값을 추출하려면 데이터 세트.data or 데이터 세트['data']헤주면 됨\n",
    "# iris_df['label'] = iris.target: '데이터 프레임'에 iris.target인 0~2를 함께 볼수 있도록 'label'이라는 이름의 열을 추가\n",
    "# 그러면 데이터 프레임에 딕셔너리는 포함 안되고 완전히 다른건가 봄..? 질문각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f06c45-6b08-4105-9ef8-abab454b203f",
   "metadata": {},
   "source": [
    "#### +) k폴드 추후 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ced6cea8-6b0c-4331-bd4e-a31417297304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[2]\n",
      "<generator object _BaseKFold.split at 0x000002B7B6A4F200>\n"
     ]
    }
   ],
   "source": [
    "# 이 데이터를 2덩이로 나눠서 한덩이는 검증. 나머지 한덩이는 학습으로 분할하는걸 각각 다르게! 2번 해줌.\n",
    "X=[1,2,3]\n",
    "kfold=KFold(n_splits=2)\n",
    "for train_index, test_index in kfold.split(X): \n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "print(kfold.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87f7eb96-ad16-4eee-b6c2-7c83ab26edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[0]\n",
      "[0 2]\n",
      "[1]\n",
      "[0 1]\n",
      "[2]\n",
      "<generator object _BaseKFold.split at 0x000002B7B6A74190>\n"
     ]
    }
   ],
   "source": [
    "# 이 데이터를 3덩이로 나눠서 1/3은 검증,2/3은 학습으로 분할하는 걸 3번한다.\n",
    "# 그리고 split의 값은 인덱스로 나온다.\n",
    "X=[1,2,3]\n",
    "kfold=KFold(n_splits=3)\n",
    "for train_index, test_index in kfold.split(X): \n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "print(kfold.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9aabdad6-510f-4b84-86be-78770c9cff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차 검증:1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "0    20\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    30\n",
      "Name: label, dtype: int64\n",
      "##교차 검증:2\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "1    40\n",
      "0    30\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    20\n",
      "1    10\n",
      "Name: label, dtype: int64\n",
      "##교차 검증:3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "1    20\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    30\n",
      "Name: label, dtype: int64\n",
      "##교차 검증:4\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    40\n",
      "2    30\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    20\n",
      "1    10\n",
      "Name: label, dtype: int64\n",
      "##교차 검증:5\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    30\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# train_test_Split 메서드도 이 모듈에 있었음\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('##교차 검증:{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b432576-30c5-43a1-86bb-950009be0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이게 내가 헷갈렸던게 3가지의 다른 레이블을 가진 150개의 데이터를 50개씩 3개의 덩어리로 나눠 예측하니까 \n",
    "#학습데이터와 검증 데이터의 레이블이 겹칠수가 없음. 따라서 정확도가 0이 나올수 밖에 없는 구조임\n",
    "#(그래서 이거 대안책이 StratifiedKFold임 <-전체 레이블 값의 분포도를 반영하게 해줌)\n",
    "\n",
    "#반면 3가지의 다른 레이블을 가진 150개의 데이터를 30개씩 5개의 덩어리로 나눠 예측하면 학습데이터와 검증 데이터의\n",
    "#레이블이 겹침. 그래서 정확도가 꽤 괜찮게 나옴. 이건 위의 식의 학습 및 검증 레이블 데이터 분포 참고하면 알수 있음\n",
    "\n",
    "# +)참고로, 같은 데이터라고 조합이 다르면 다른 정확도가 나올수 있음. 위의 ##교차검증:1과 ##교차검증:5에서 처럼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27049731-92f8-4d5f-9eb1-dda2209e1e35",
   "metadata": {},
   "source": [
    "### StratifiedKFold\n",
    "* KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결해줌\n",
    "* 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에, split() 메서드에 인자로 피처뿐만 아니라 레이블 데이터 세트도 반드시 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ac1772-f206-4bc1-8847-c6ad6984e811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter +=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
    "    \n",
    "# 아래 출력 결과를 보면 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당됐음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2d70d-d305-4b7e-afe3-5e564722dd50",
   "metadata": {},
   "source": [
    "##### -StratifiedKFoldfmf 이용해 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c7655d0-e0b0-44fd-b45b-dfc3aa6fac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "#StratifiedKFold의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test=features[train_index],features[test_index]\n",
    "    y_train, y_test=label[train_index], label[test_index]\n",
    "    #학습 및 에측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    \n",
    "    #반복 시마다 정확도 측정\n",
    "    n_iter +=1\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "#교차 검증별 정확도 및 평균 정확도 계산\n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy,4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63046c2-ae7e-43ab-9e09-d0aa7cebc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기서 질문이 features의 값을 인덱스로 바꾸고 다시 값으로 반환해 주는 건가?\n",
    "#print('~~')쓸때 {0}, {1}이 있으면 그 순서에 맞게 format( , )있어야 함, {0}이런거 없으면 그냥 뒤에 오는 값 넣주기\n",
    "# +)사실 k폴드가 아니라 StratifiedKFold를 쓰는게 맞음\n",
    "# 근데 회귀에서는 StratifiedKFold를 지원하지 않음. \n",
    "# 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분초를 정하는 의미가 없다.\n",
    "# 그래서 다음으로 이런 교차 겁증을 보다 간편하게 제공해주는 사이킷런의 API를 살펴볼거당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237cf9d-3763-4961-8a36-90961de130a7",
   "metadata": {},
   "source": [
    "### cross_val_score() : 교차 검증을 보다 간편하게 제공해주는 사이킷런의 API \n",
    "* KFold의 과정을 한꺼번에 수행하는 API임\n",
    "* (1) 폴드 세트 설정, (2) for 루프 반복으로 학습 및 테스트 데이터의 인덱스를 추출,(3) 반복적으로 학습과 예측을 수행하고 예측수행을 반환 -->이 과정을 한꺼번에\n",
    "* cross_val_score( estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs' ) 형태로 이뤄짐\n",
    "* cross_val_score( 사이킷런의 분류 또는 회귀 알고리즘, 피처 데이터 세트, 레이블 데이터 세트, 예측 성능 평가, 교차 검증 폴드 수, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c1d3f4d-5ab3-4756-9416-dc633f18964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data=load_iris()\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data=iris_data.data\n",
    "label=iris_data.target\n",
    "\n",
    "#성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores=cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도:',np.round(scores,4))\n",
    "print('평균 검증 정확도:' ,np.round(np.mean(scores),4))\n",
    "\n",
    "#cross_val_score()에 classifier가 입력되면 기본적으로 Stratified K폴드 방식으로 레이블값의 분포에 따라 \n",
    "# 학습 및 테스트 세트로 분할 하는데, 회귀인 경우 Stratified K폴드 방실으로 분할 못해서 K폴드 방식으로 분할함\n",
    "#질문인데 cross_val_score에서 '사이킷런의 분류 또는 회귀 알고리즘' 자리에 의사결정 트리가 왜 나와?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c24b9-bd13-409f-afc9-041fcf1b8b42",
   "metadata": {},
   "source": [
    "##### +) cross_validate: cross_val_score()와는 달리 여러개의 평가 지표를 반환할수 있음. 일단 건너뛰겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d62c14-4857-4878-b1b4-e1118704c18c",
   "metadata": {},
   "source": [
    "### GridSearchCV: 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 할수 있음\n",
    "* 하이퍼 파라미터는 머신러닝 알고리즘을 구성하는 주요 구성 요소이며, 이 값을 조정해 알고리즘의 예측성능을 개선할 수 있다.\n",
    "* GridSearchCV API를 이용해 분류나 회귀 알고리즘에 이용되는 하이퍼 파라미터를 순차적으로 이력하며 최적의 파라미터 도출할 수 있는 방안을 제공(촘촘하게 파라미터 입력하며 테스트 하는 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851aaa1-fca0-472c-b3f9-fdc8be234ac5",
   "metadata": {},
   "source": [
    "-하이퍼 파라미터를 순차적으로 변경하며 최적의 파라미터 도출하고자 한다면 다음과 같이 파라미터 집합을 만들고 이를 순차적으로 적용하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b3719414-7666-4bf8-ae8a-542cafd6d7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#얘는 왜쓴건지 모르겠네..\n",
    "grid_parameters={'max_depth':[1,2,3],\n",
    "                 'min_samples_split':[2,3]\n",
    "                }\n",
    "grid_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b943aa-21c0-4055-91e2-bdbe49c4f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv가 3회라면 개별 파라미터 조합마다 3개의 폴딩 세트를 3회에 걸쳐 학습 및 평가에 쳥균값으로 성능을 측정함\n",
    "#6개의 파라미터 조합이라면 총 cv 3회* 6개의 파라미터 조합=18회의 학습 및 평가가 이뤄짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b8fd89b-6272-448d-b1be-39002fcc67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data=load_iris()\n",
    "X_train, X_test, y_train, y_test=train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree=DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters={'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a9c9c8-b39f-454b-933f-a8745e748f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나ㄴ우어 테스트 수행 설정.\n",
    "### refit=True가 기본값임. True이면 가장 좋은 마파미터 설정으로 재학습시킴.\n",
    "grid_dtree=GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "#붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "#GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
